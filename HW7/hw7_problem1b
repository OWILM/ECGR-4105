# HW7 Problem 1b — Extended CNN (3 Conv Layers)

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import time

# Use GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using:", device)


# CIFAR-10 Preprocess
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))
])

train_set = torchvision.datasets.CIFAR10(root="./data", train=True,
                                         download=True, transform=transform)
test_set  = torchvision.datasets.CIFAR10(root="./data", train=False,
                                         download=True, transform=transform)

train_loader = DataLoader(train_set, batch_size=64, shuffle=True)
test_loader  = DataLoader(test_set, batch_size=64, shuffle=False)


# Problem 1b CNN  model (3 Conv Layers)
class CNN_1B(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)

        self.fc1 = nn.Linear(64 * 4 * 4, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = F.max_pool2d(torch.tanh(self.conv1(x)), 2)
        x = F.max_pool2d(torch.tanh(self.conv2(x)), 2)
        x = F.max_pool2d(torch.tanh(self.conv3(x)), 2)
        x = x.view(-1, 64 * 4 * 4)
        x = torch.tanh(self.fc1(x))
        return self.fc2(x)

# Train and Validation
def train_one_epoch(model, loader, loss_fn, optimizer):
    model.train()
    total_loss, correct, total = 0, 0, 0

    for imgs, labels in loader:
        imgs, labels = imgs.to(device), labels.to(device)

        outputs = model(imgs)
        loss = loss_fn(outputs, labels)
        total_loss += loss.item()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        _, pred = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (pred == labels).sum().item()

    return total_loss / len(loader), correct / total


def evaluate(model, loader, loss_fn):
    model.eval()
    total_loss, correct, total = 0, 0, 0

    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)

            outputs = model(imgs)
            loss = loss_fn(outputs, labels)
            total_loss += loss.item()

            _, pred = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (pred == labels).sum().item()

    return total_loss / len(loader), correct / total

# Training Loop
model = CNN_1B().to(device)
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

epochs = 50

train_losses, val_losses = [], []
train_accs, val_accs = [], []

start = time.time()

for epoch in range(1, epochs + 1):
    tloss, tacc = train_one_epoch(model, train_loader, loss_fn, optimizer)
    vloss, vacc = evaluate(model, test_loader, loss_fn)

    train_losses.append(tloss)
    val_losses.append(vloss)
    train_accs.append(tacc)
    val_accs.append(vacc)

    print(f"Epoch {epoch}/{epochs} | "
          f"Train Loss: {tloss:.4f} | Val Loss: {vloss:.4f} | "
          f"Train Acc: {tacc:.4f} | Val Acc: {vacc:.4f}")

end = time.time()
print(f"\nTraining Time: {(end - start)/60:.2f} minutes")

# Plots
plt.figure(figsize=(14,5))

plt.subplot(1,2,1)
plt.plot(train_losses, label="Training Loss")
plt.plot(val_losses,   label="Validation Loss")
plt.title("Problem 1b — Loss Over Epochs")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.subplot(1,2,2)
plt.plot(train_accs, label="Training Accuracy")
plt.plot(val_accs,   label="Validation Accuracy")
plt.title("Problem 1b — Accuracy Over Epochs")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

plt.show()
